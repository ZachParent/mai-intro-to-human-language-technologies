{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1710a7e6",
   "metadata": {},
   "source": [
    "# IHLT Lab 4: Part of Speech\n",
    "\n",
    "**Authors:** *Zachary Parent ([zachary.parent](mailto:zachary.parent@estudiantat.upc.edu)), Carlos Jim√©nez ([carlos.humberto.jimenez](mailto:carlos.humberto.jimenez@estudiantat.upc.edu))*\n",
    "\n",
    "### 2024-10-10\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Consider Treebank corpus.\n",
    "\n",
    "    - Train HMM, TnT, perceptron and CRF models using the first 500, 1000, 1500, 2000, 2500 and 3000 sentences.\n",
    "\n",
    "    - Evaluate the resulting 24 models using sentences from 3001.\n",
    "\n",
    "2. Provide a figure with four learning curves, each per model type (X=training set size; Y=accuracy).\n",
    "\n",
    "    - Which model would you select? Justify the answer.\n",
    "\n",
    "\n",
    "## Notes\n",
    "\n",
    "we should measure the time it takes to train each model.\n",
    "\n",
    "we could also measure the time it takes to make inferences on the test set\n",
    "\n",
    "we should plot the accuracy vs the number of sentences.\n",
    "\n",
    "we could create a ratio of accuracy vs training time for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b21e09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/zachparent/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22a4a11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7854550d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('chairman', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Elsevier', 'NNP'),\n",
       " ('N.V.', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('Dutch', 'NNP'),\n",
       " ('publishing', 'VBG'),\n",
       " ('group', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.treebank.tagged_sents()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c63d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learning the model\n",
    "\n",
    "def hidden_markov(train, test):\n",
    "    def LID(fd, bins):\n",
    "        return nltk.probability.LidstoneProbDist(fd, 0.1, bins)\n",
    "    \n",
    "    trainer = nltk.tag.hmm.HiddenMarkovModelTrainer()\n",
    "    HMM = trainer.train_supervised(train, estimator=LID)\n",
    "    acc = HMM.accuracy(test)\n",
    "\n",
    "    return acc\n",
    "\n",
    "# set(test)\n",
    "# len(set(test).difference(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b4d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM = nltk.HiddenMarkovModelTagger.train(train)\n",
    "# HMM.accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c1deb6",
   "metadata": {},
   "source": [
    "## TnT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4cb776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def TnT(train, test):\n",
    "    TnT = nltk.tag.tnt.TnT()\n",
    "    TnT.train(train)\n",
    "    acc = TnT.accuracy(test)\n",
    "\n",
    "    return acc\n",
    "#     TnT.tag(['the', 'men', 'attended', 'to', 'the', 'meetings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38d517",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bc105f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(train, test):\n",
    "    PER = nltk.tag.perceptron.PerceptronTagger(load=False)\n",
    "    PER.train(train)\n",
    "    acc = PER.accuracy(test)\n",
    "\n",
    "    return acc\n",
    "# PER.tag(['the', 'men', 'attended', 'to', 'the', 'meetings']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add637c",
   "metadata": {},
   "source": [
    "# CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d803196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7df68faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRF(train, test):\n",
    "    CRF = nltk.tag.CRFTagger()\n",
    "    CRF.train(train,'crf_tagger_model')\n",
    "    acc = CRF.accuracy(test)\n",
    "    \n",
    "    return acc\n",
    "    # CRF.tag(['the', 'men', 'attended', 'to', 'the', 'meetings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428dc310",
   "metadata": {},
   "source": [
    "## Train all models with different sentences number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb342d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences number list\n",
    "sentences_n = [500, 1000, 1500, 2000, 2500, 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6448890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 500 sentences...\n",
      "HMM    0.595683\n",
      "TnT    0.520181\n",
      "PER    0.716771\n",
      "CRF    0.749320\n",
      "Name: 0, dtype: float64\n",
      "Training with 1000 sentences...\n",
      "HMM    0.673818\n",
      "TnT    0.587222\n",
      "PER    0.800863\n",
      "CRF    0.830175\n",
      "Name: 1, dtype: float64\n",
      "Training with 1500 sentences...\n",
      "HMM    0.715001\n",
      "TnT    0.640276\n",
      "PER    0.851068\n",
      "CRF    0.863976\n",
      "Name: 2, dtype: float64\n",
      "Training with 2000 sentences...\n",
      "HMM    0.732225\n",
      "TnT    0.668250\n",
      "PER    0.863933\n",
      "CRF    0.877013\n",
      "Name: 3, dtype: float64\n",
      "Training with 2500 sentences...\n",
      "HMM    0.745737\n",
      "TnT    0.686682\n",
      "PER    0.878351\n",
      "CRF    0.885733\n",
      "Name: 4, dtype: float64\n",
      "Training with 3000 sentences...\n",
      "HMM    0.755752\n",
      "TnT    0.700842\n",
      "PER    0.883877\n",
      "CRF    0.890222\n",
      "Name: 5, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "test = nltk.corpus.treebank.tagged_sents()[3000:]\n",
    "\n",
    "results = pd.DataFrame(columns=['HMM', 'TnT', 'PER', 'CRF'], dtype=float)\n",
    "\n",
    "for n in sentences_n:\n",
    "    print(f'Training with {n} sentences...')\n",
    "    train = nltk.corpus.treebank.tagged_sents()[:n]\n",
    "\n",
    "    # TODO:remove\n",
    "    train = train[:len(train)//10]\n",
    "    \n",
    "    hmm_acc = hidden_markov(train, test)\n",
    "    tnt_acc = TnT(train, test)\n",
    "    per_acc = perceptron(train, test)\n",
    "    crf_acc = CRF(train, test)\n",
    "\n",
    "    new_row = pd.DataFrame({'HMM': [hmm_acc], 'TnT': [tnt_acc], 'PER': [per_acc], 'CRF': [crf_acc]})\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "    print(results.iloc[-1, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccde1a",
   "metadata": {},
   "source": [
    "## Do your thing Zach with the plots ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d11f8",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\"\"\"\n",
    "\n",
    "Provide a figure with four learning curves, each per model type (X=training set size; Y=accuracy).\n",
    "\n",
    "Which model would you select? Justify the answer.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c28dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f60f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
